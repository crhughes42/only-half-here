---
title: "Homework Ten"
author: "Chelsea Hughes"
output:
  word_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data"
data1 <- read.table(url, stringsAsFactors = FALSE, header = FALSE, sep = ",")
library(knitr) 
library(caret) 
library(kknn)
library(klaR)
library(ggplot2)
library(shiny)
library(kernlab)
library(e1071)
library(DAAG)
set.seed(1042)
```

## Question 14.1 
**The breast cancer data set breast-cancer-wisconsin.data.txt from the website has missing values.**
- 1. Use the mean/mode imputation method to impute values for the missing data.
- 2. Use regression to impute values for the missing data.
- 3. Use regression with perturbation to impute values for the missing data.
- 4. (Optional) Compare the results and quality of classification models (e.g., SVM, KNN) build using (1) the data sets from questions 1,2,3; (2) the data that remains after data points with missing values are removed; and (3) the data set when a binary variable is introduced to indicate missing values.

# 14.1.1
```{r, include=TRUE}

#visualize data 
head(data1) 

#find missing values 
colSums(data1 == '?')
data1[data1$V7 == '?',]
missingnumbers = 100*nrow(data1[data1$V7=='?',])/nrow(data1)
missingnumbers 
ggplot(data1, aes(x = V7)) +geom_bar()

#find missing indices 
mode1 <- function(x) {
mode2 <- unique(x)
mode2[which.max(tabulate(match(x, mode2)))]
}

#find mode for data not missing in V7
missingindices <- which(data1$V7 == '?', arr.ind = TRUE)
mode3 <- as.numeric(mode1(data1[-missingindices, 'V7']))
mode3

#mode imputation 
imputation1 <- data1 
imputation1[missingindices, 'V7'] <- mode3

#check for missing values 
colSums(imputation1 == '?') 

#find mean for data not missing in V7
mean1 <- mean(as.integer(data1[-missingindices, 'V7']))
mean1

#mean imputation 
mean2 <- data1 
mean2[missingindices, 'V7'] <- as.integer(mean1)

#check for missing values 
colSums(mean2 == '?') 

```

# 14.1.2
```{r, include=TRUE}

#regression imputation 
regression1 <- data1[-missingindices, 2:10]

#visualize data 
head(regression1)
model1 <- lm(V7~., data = regression1)
summary(model1)
step(model1) 
model2 <- lm(V7 ~ V2 + V4 + V5 + V8, data = regression1)
summary(model2)

#cross validation 
regression2 <- as.integer(regression1$V7)
cv1 <- trainControl(method = "repeatedcv", repeats = 4, number = 6)
print(cv1)

#regression imputation 
imputation2 <- predict(model2, data1[missingindices,])
pertubation3 <- predict(model2, newdata = data1[missingindices,])
pertubation4 <- rnorm(nrow(data1[missingindices,]), pertubation3, sd(pertubation3))
pertubation5 <- data1
pertubation5[missingindices,]$V7 <- pertubation4
pertubation5$V7 <- as.numeric(pertubation5$V7)


#check value range 
imputation2
imputation3 <- data1
imputation3[missingindices, 'V7'] <- imputation2 
imputation4 <- as.integer(imputation3$V7)
imputation4[imputation4 > 10] <- 10 
imputation4[imputation4 < 1] <- 1 
```

# 14.1.3 
```{r}

#imputation using regression pertubation
pertubation1 <- data1
pertubation1[missingindices, 'V7'] <-  rnorm(length(imputation2), imputation2, sd(imputation2))

#check values 
pertubation2 <- as.integer(pertubation1$V7)
pertubation2[pertubation2 > 10] <- 10 
pertubation2[pertubation2 < 1] <- 1 

#ensure values are between 0-10
plot(pertubation2, col = "mediumaquamarine", pch = 20)

```

# 14.1.4: KNN
```{r, include=TRUE}

#split into training and testing, use for KNN and SVM
train1 <- sample(nrow(data1), size = floor(nrow(data1) * .8))
test1 <- setdiff(1:nrow(data1), train1)

#mode imputation
imputation1$V7 <- as.integer(imputation1$V7)
for (k in 1:5) { 
knnmodel1 <- kknn(V11 ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10, imputation1[train1,], imputation1[test1,], k=k)

#compare mode imputation
pred1 <- as.integer(fitted(knnmodel1) + 0.5) 
acc1 <- sum(pred1 == imputation1[test1,]$V11)/nrow(imputation1[test1,])
print(acc1)
} 

#mean imputation 
mean2$V7 <- as.integer(mean2$V7)
for (k in 1:5) { 
knnmodel2 <- kknn(V11 ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10, mean2[train1,], mean2[test1,], k=k)

#compare mean imputation
pred2 <- as.integer(fitted(knnmodel2) + 0.5) 
acc2 <- sum(pred2 == mean2[test1,]$V11) / nrow(mean2[test1,])
print(acc2)
} 

#regression imputation 
imputation3$V7 <- as.integer(imputation3$V7)
for (k in 1:5) { 
knnmodel3 <- kknn(V11 ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10, imputation3[train1,],  imputation3[test1,], k=k)

#compare regression imputation 
pred3 <- as.integer(fitted(knnmodel3) + 0.5) 
acc3 <- sum(pred3 == imputation3[test1,]$V11) / nrow(imputation3[test1,])
print(acc3)
}

#regression pertubation imputation 
pertubation1$V7 <- as.integer(pertubation1$V7)
for (k in 1:5) { 
knnmodel4 <- kknn(V11 ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10, pertubation1[train1,], pertubation1[test1,], k=k)

#compare pertubation imputation
pred4 <- as.integer(fitted(knnmodel4) + 0.5) 
acc4 <- sum(pred4 == pertubation1[test1,]$V11) / nrow(pertubation1[test1,])
print(acc4)
}

#deal with missing values 
dropdata1 <- (data1[-missingindices,])
dropdata1$V7 <- as.integer(dropdata1$V7)
droptrain1 <- sample(nrow(dropdata1), size = floor(nrow(dropdata1) * .8)) 
droptest1 <- setdiff(1:nrow(dropdata1), train1) 

for (k in 1:5) { 
knnmodel5 <- kknn(V11 ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10, dropdata1[droptrain1, ], dropdata1[droptest1, ], k=k)

#compare with validation
pred5 <- as.integer(fitted(knnmodel5) + 0.5) 
acc5 <- sum(pred5 == dropdata1[droptest1,]$V11) / nrow(dropdata1[droptest1,])
print(acc5)
}

#use interaction 
binarydata1 <- data1 
binarydata1$V12[data1$V7 == "?"] <- 0 
binarydata1$V12[data1$V7 != "?"] <- 1 

#create interaction factors 
binarydata1$V13[data1$V7 == "?"] <- 0 
binarydata1$V13[data1$V7 != "?"] <- - as.integer(data1[-missingindices,]$V7)

binarydata1$V12 <- as.integer(binarydata1$V12)
for (k in 1:5) {
knnmodel6 <- kknn(V11 ~ V2 + V3 + V4 + V5 + V6 + V8 + V9 + V10+V13, binarydata1[train1, ], binarydata1[test1, ], k=k)

#compare with validation
pred6 <- as.integer(fitted(knnmodel6) + .5) 
acc6 <- sum(pred6 == binarydata1[test1,]$V11) / nrow(binarydata1[test1,])
print(acc6)
}

```
**I had some problems with KNN...... The problems with KNN, was that I kept getting 'out of bound subscript' errors. Although, after some heavy debugging research, I added "...$V7 <- as.integer(...$V7)" to each chuck and that seemed to solve the problem. [1]**   
  
What I found interesting enough to note was that the performace variation wasn't as great as I anticipated it would be with a data set with missing values. I'm assuming that's just because there weren't enough missing values or I just did it wrong (which is always a possibility).   

# 14.1.4: SVM
```{r, include=TRUE}

#use same 5 classifiers as KNN
c1 <- c(1, 2, 3, 4, 5) 

#mode imputation
for (i in 1:5) {
svmmodel1 <- ksvm(as.matrix(imputation1[train1,2:10]), as.factor(imputation1[train1,11]),type = "C-svc", kernel = "anovadot", C = c1[i])
print(svmmodel1)  

#compare mode imputation
pred7 <- predict(svmmodel1, imputation1[test1,2:10])
acc7 <- sum(pred7 == imputation1[test1,11]) / nrow(imputation1[test1,])
print(acc7)
}

#mean imputation 
for (i in 1:5) {
svmmodel2 <- ksvm(as.matrix(mean2[train1,2:10]), as.factor(mean2[train1,11]),type = "C-svc", kernel = "anovadot", C = c1[i])

#compare mean imputation
pred8 <- predict(svmmodel2, mean2[test1,2:10])
acc8 <- sum(pred8 == mean2[test1,11]) / nrow(mean2[test1,])
print(acc8)
}

#regression imputation
for (i in 1:5) {
svmmodel3 <- ksvm(as.matrix(pertubation5[train1,2:10]),as.factor(pertubation5[train1,11]), type = "C-svc",kernel = "vanilladot", C = c1[i])
  
#compare regression imputation
pred9 <- predict(svmmodel3, pertubation5[test1,2:10])
acc9 <- sum(pred9 == pertubation5[test1,11]) / nrow(pertubation5[test1,])
print(acc9)
}

#deal with missing values
for (i in 1:5) {
svmmodel5 <- ksvm(as.matrix(dropdata1[droptrain1,2:10]), as.factor(dropdata1[droptrain1,11]), type = "C-svc", kernel = "vanilladot", C = c1[i])

#compare with validation
pred11 <- predict(svmmodel5, dropdata1[droptrain1,2:10])
acc11 <- sum(pred11 == dropdata1[droptrain1,11]) / nrow(data1[droptrain1,])
print(acc11)
}

#use interaction factors
for (i in 1:5) {
svmmodel6 <- ksvm(as.matrix(binarydata1[train1,c(2:6,8:10,13)]), as.factor(binarydata1[train1,11]),type = "C-svc", kernel = "vanilladot", C = c1[i])
  
#compare with validation
pred12 <- predict(svmmodel6, binarydata1[test1,c(2:6,8:10,13)])
acc12 <- sum(pred12 == binarydata1[test1,11]) / nrow(binarydata1[test1,])
print(acc12)
}
```
**I also had issues with SVM, specifically in reference to pertubation. It was a great deal of debugging and code changing (that I'm not sure is accurate) to make the model run. I played with some different kernels: Ploydot, Vanilladot, Rbfdot and Matrix but honestly, they all seemed to produce about the same. I would assume you would want use the simplier kernels in real life but I wanted to have an exploratory experiment with homework. On that subject, you'll notice that I switched with regression... For whatever reason, I couldn't debug why it would only let me use 'Vanilladot'.**  
  
SVM was easier to do, it also ended up producing more consistency. Both models predicted high accuracy but KNN had more variation so I think I would end up using the SVM approach.  
  
## Question 15.1 
**Describe a situation or problem from your job, everyday life, current events, etc., for which optimization would be appropriate. What data would you need?** 
Now that I'm approaching real adulthood (30), I'm starting to consider the option of investing expendable income opposed to just stuffing it away in a savings account. As someone completely new to the idea of investing, optimization could help me determine which funds to allocate to which stocks that would minimize my risk and target my return. We would need data for all stocks chosen for a time period that would indiciate the stability of the stock (significant increases, decreases or general irratic behavior). 
stock <- valuable stocks <- funds available for placement 
risk <- historical data of stock patterns 


## References 
[1][links]https://adv-r.hadley.nz/debugging.html